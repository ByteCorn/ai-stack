version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./webui_data:/app/backend/data
    depends_on:
      - ollama
    restart: unless-stopped


  forgejomcp:
    build:
      context: .
      dockerfile: forgejomcp.dockerfile
    environment:
      - FORGEJO_URL=https://codeberg.org
      - FORGEJO_ACCESS_TOKEN=747590d10aa861ebdb44c374e2280854dbfaf81a
      - FORGEJO_DEBUG=true
    ports:
      - "8080:8080"
    restart: unless-stopped
    command: ["--transport", "sse", "--debug"]

  opencode:
    # image: ghcr.io/anomalyco/opencode:latest
    build:
      context: .
      dockerfile: opencode.dockerfile
    ports:
      - "4096:4096"
    volumes:
      - ./opencode_config:/config
      - ./opencode_projects:/projects
      # - ./opencode_state:/state
    # command: ["serve", "--hostname=0.0.0.0"]
    command: web --hostname 0.0.0.0 --port 4096
    environment:
      - OPENCODE_CONFIG=/config/opencode.json
      # - XDG_STATE_HOME=/state
    working_dir: /projects
    restart: unless-stopped
